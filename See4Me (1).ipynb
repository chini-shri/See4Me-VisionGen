{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Project Name - VisionGen\n"
      ],
      "metadata": {
        "id": "zu9i8nXqTruL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ This project generates captions for images and videos using a vision-language model (BLIP), and converts them into speech using gTTS ‚Äî creating a multi-sensory AI experience.\n"
      ],
      "metadata": {
        "id": "mgcOJAn8vmN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate torchvision opencv-python pyttsx3 sentencepiece\n"
      ],
      "metadata": {
        "id": "Igtx70u6NwOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import torch\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the processor and model\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "CokXl33KOo8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image upload - Captioning\n",
        "print(\"üì∑ Upload an image file\")\n",
        "uploaded_img = files.upload()\n",
        "img_path = next(iter(uploaded_img))\n",
        "image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "out = model.generate(**inputs)\n",
        "caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"\\nüñºÔ∏è Image Caption: {caption}\")\n"
      ],
      "metadata": {
        "id": "xcbMukWBOq7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Video uploading\n",
        "print(\"\\nüé¨ Upload a video file\")\n",
        "uploaded_vid = files.upload()\n",
        "vid_path = next(iter(uploaded_vid))\n",
        "\n",
        "cap = cv2.VideoCapture(vid_path)"
      ],
      "metadata": {
        "id": "PRjaBBYyPJdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Frames\n",
        "frames = []\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frames.append(frame)\n",
        "cap.release()\n",
        "print(f\"\\nüìπ Extracted {len(frames)} frames from the video.\")"
      ],
      "metadata": {
        "id": "DTxgLzO6PNe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captions = []\n",
        "\n",
        "# Caption every 5th frame\n",
        "for i in range(0, len(frames), 5):\n",
        "    img = Image.fromarray(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB))\n",
        "    inputs = processor(images=img, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Beam search for better results\n",
        "    out = model.generate(**inputs, num_beams=5, max_length=50, early_stopping=True)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "    captions.append((i, caption))\n",
        "    print(f\"üñºÔ∏è Frame {i}: {caption}\")\n"
      ],
      "metadata": {
        "id": "MYqsjgiSPQ8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"video_frame_captions.txt\", \"w\") as f:\n",
        "    for idx, cap in captions:\n",
        "        f.write(f\"Frame {idx}: {cap}\\n\")\n",
        "\n",
        "print(\"\\n‚úÖ Captions saved to video_frame_captions.txt\")\n"
      ],
      "metadata": {
        "id": "syEVnNUVkL-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"video_frame_captions.txt\")\n"
      ],
      "metadata": {
        "id": "iuHMY2MYreeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS\n"
      ],
      "metadata": {
        "id": "-BhIRtGVt-wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "caption_text = \"A dog playing with a ball in the garden.\"  # Replace with your caption\n",
        "tts = gTTS(text=caption_text, lang='en')\n",
        "tts.save(\"caption_audio.mp3\")\n",
        "\n",
        "# Play audio in notebook\n",
        "Audio(\"caption_audio.mp3\")\n"
      ],
      "metadata": {
        "id": "zgOvqUkEuCFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, cap in captions:\n",
        "    print(f\"üñºÔ∏è Frame {i}: {cap}\")\n",
        "\n",
        "    tts = gTTS(text=cap, lang='en')\n",
        "    filename = f\"frame_{i}_audio.mp3\"\n",
        "    tts.save(filename)\n",
        "\n",
        "    display(Audio(filename))\n"
      ],
      "metadata": {
        "id": "b81KTXrbuJ3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(\"caption_audio.mp3\", autoplay=True)\n"
      ],
      "metadata": {
        "id": "dm96_URLuPE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"all_captions.txt\", \"w\") as f:\n",
        "    for i, cap in captions:\n",
        "        f.write(f\"Frame {i}: {cap}\\n\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"all_captions.txt\")\n"
      ],
      "metadata": {
        "id": "-SmoKPjAuZL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}